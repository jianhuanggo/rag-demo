from _embedding import gpt4all_embedding
from _vectordb import sqllite
from _config import _config as _config_
from _common import _common as _common_
from _data import _data_load
from _llm import langchain


@_common_.exception_handler
def run(query: str, filepath: str = "") -> str:
    """
    Executes a retrieval-based QA (Question Answering) process using a specified query.

    This function configures and initiates a retrieval-based QA system. It either loads text data
    from a given file or uses an existing database, and then sets up a retriever model using embeddings
    generated by the `gpt4all_embedding` function. The QA process is performed using a combination of
    the retriever and a language model (like GPT-4).

    Args:
        query (str): The query or question for which an answer is sought.
        filepath (str, optional): The path to a file containing text data. If provided, the text data is
            loaded and used in the retrieval process. Defaults to an empty string, in which case an existing
            database is used.

    Returns:
        str: The answer generated by the retrieval-based QA system.

    """
    _config = _config_.PGConfigSingleton()

    if filepath:
        texts = _data_load.load_document(filepath)
        _retriever = sqllite.get_vector_db(gpt4all_embedding.gpt4all_embedding(),
                                           texts=texts).as_retriever(search_kwargs={"k": _config.config.get("model_knn_cnt")})
    else:
        _retriever = sqllite.get_vector_db(gpt4all_embedding.gpt4all_embedding()).as_retriever(search_kwargs={"k": _config.config.get("model_knn_cnt")})

    _qa = langchain.qa_chain(_retriever)
    return _qa.run(query)








